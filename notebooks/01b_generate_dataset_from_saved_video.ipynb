{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd218d3e-9937-4940-9a09-4d74a9fbcda1",
   "metadata": {},
   "source": [
    "# Extract images from a video and add them to a dataset\n",
    "\n",
    "This notebook is similar to the previous one but the source of the images to label will be a video.\n",
    "\n",
    "As an example here, we will generate the video from a camera and then work from the video.\n",
    "\n",
    "\n",
    "You eventually want to have at least 500 images in your dataset. You can start with 100-200 images and go through all notebooks. You can always add more images and re-train your network. \n",
    "\n",
    "You probably want a minimum of 150 images to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f49225de-4b8a-43c1-a16b-2e4776010a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from ipyevents import Event \n",
    "import threading\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "from unetTracker.trackingProject import TrackingProject\n",
    "from unetTracker.dataset import UNetDataset\n",
    "from unetTracker.camera import USBCamera, bgr8_to_jpeg\n",
    "from unetTracker.unetGUI import LabelFromImagesGUI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8958448-ee53-4a60-92ef-d049cd78b0ad",
   "metadata": {},
   "source": [
    "Load a project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f57b9032-7ed7-4ec1-bda6-9e6a7542633c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project directory: /home/kevin/Documents/trackingProjects/faceTrack\n",
      "Loading /home/kevin/Documents/trackingProjects/faceTrack/config.yalm\n",
      "{'augmentation_HorizontalFlipProb': 0.0, 'augmentation_RandomBrightnessContrastProb': 0.2, 'augmentation_RandomSizedCropProb': 1.0, 'augmentation_RotateProb': 0.3, 'image_size': [480, 640], 'labeling_ImageEnlargeFactor': 2.0, 'name': 'faceTrack', 'normalization_values': {'means': [0.5110162496566772, 0.4608974754810333, 0.4772901237010956], 'stds': [0.2727729380130768, 0.2578601539134979, 0.256255567073822]}, 'object_colors': [(0.0, 0.0, 255.0), (255.0, 0.0, 0.0), (255.0, 255.0, 0.0), (128.0, 0.0, 128.0)], 'objects': ['nose', 'chin', 'rEye', 'lEye'], 'target_radius': 10}\n"
     ]
    }
   ],
   "source": [
    "project = TrackingProject(name=\"faceTrack\",root_folder = \"/home/kevin/Documents/trackingProjects/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b39940d-b495-4448-851f-338181f6d5f7",
   "metadata": {},
   "source": [
    "Create a dataset for the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9101ed9a-33e9-4476-a552-97c826933188",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = UNetDataset(image_dir=project.image_dir, mask_dir=project.mask_dir, coordinate_dir=project.coordinate_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3865711d-c42b-4db0-948d-baec6dad5dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in the dataset: 687\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of images in the dataset:\",len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4580224a-9506-4d74-9736-9f45052a1851",
   "metadata": {},
   "source": [
    "## Extract frames from a video\n",
    "\n",
    "You need to select a directory in which the individual extracted frames will be saved. Here I used a directory within my project directory.\n",
    "\n",
    "Images will be added to any image that is already in the folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4923f1e7-a96e-47b3-bb05-48e3a84a1890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kevin/Documents/trackingProjects/faceTrack/extracted_frames/\n"
     ]
    }
   ],
   "source": [
    "#video_fn = \"/ext_drives/d69/data/electro/fjk9263/fjk9263-17112022-1221/output.mp4\"\n",
    "video_fn = '/tmp/video1.avi'\n",
    "extracted_frame_dir = project.project_dir+\"/extracted_frames/\"\n",
    "print(extracted_frame_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29807bbc-d6e5-4c6a-9a3a-317f0fa234af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video length: 600, image size: 480h640w\n",
      "Extracting frames: [397] to /home/kevin/Documents/trackingProjects/faceTrack/extracted_frames/\n"
     ]
    }
   ],
   "source": [
    "dataset.extract_frames_from_video(video_fn,1,extracted_frame_dir,project.image_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1a6edf-224e-4839-8414-c207402e9ff5",
   "metadata": {},
   "source": [
    "## Label extracted frames and save to dataset\n",
    "\n",
    "We use a GUI to label the object in the extracted frames.\n",
    "\n",
    "Make sure that your image is shown at maximal size by extending the notebook window. \n",
    "Make sure the label are correctly positioned in the image below.\n",
    "\n",
    "\n",
    "1. In the large image, click on the object selected by the radio button. The label should appear in the picture below. \n",
    "2. If you don't want to save the data from a particular image, click on Next frame.\n",
    "2. Repeat for all your visible objects\n",
    "3. Click on Save labelled frame.\n",
    "4. Repeat for all your images\n",
    "\n",
    "When you click on `Save labelled frame`, the image is remove from the `extract_frame_dir` directory and transfer to your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8f021ab-4efd-4aad-a6f2-5cef5bd524fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.labeling_ImageEnlargeFactor = 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fc4beb5-a138-4f6a-aac1-08ea37ee886f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa1f93e358854a47bcf9c489951210d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='Event info'), HBox(children=(Label(value='Objects:'), RadioButtons(layout=Layout(wiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<unetTracker.unetGUI.LabelFromImagesGUI at 0x7fe117991df0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LabelFromImagesGUI(image_dir=extracted_frame_dir,project=project,dataset=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74fcac56-a48b-4c8a-8a36-1efa55ebea4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "675"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07da6837-2852-49f3-8c3f-a68fda611a73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
